import netCDF4 as nc
import numpy as np
import sys
import logging
import os
import datetime
import argparse # ğŸ’¡ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‚’æ‰±ã†ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’è¿½åŠ 

# --- ã“ã“ã«èª²é¡Œã®è¦ä»¶ã‚’å®šç¾© ---
# (REQUIREMENTSè¾æ›¸ã¯å¤‰æ›´ãªã—)
REQUIREMENTS = {
    "dimensions": {
        "lat": 480,
        "lon": 480,
    },
    "coordinates": {
        "lat": 46.95 - np.arange(480) * 0.05,
        "lon": 120.0 + np.arange(480) * 0.0625,
    },
    "input_variables": [
        'Prmsl_ft3', 'U10m_ft3', 'V10m_ft3', 'T2m_ft3', 'U975_ft3', 'V975_ft3',
        'T975_ft3', 'U950_ft3', 'V950_ft3', 'T950_ft3', 'U925_ft3', 'V925_ft3',
        'T925_ft3', 'R925_ft3', 'U850_ft3', 'V850_ft3', 'T850_ft3', 'R850_ft3',
        'GH500_ft3', 'T500_ft3', 'R500_ft3', 'GH300_ft3', 'U300_ft3', 'V300_ft3',
        'Prmsl_ft6', 'U10m_ft6', 'V10m_ft6', 'T2m_ft6', 'U975_ft6', 'V975_ft6',
        'T975_ft6', 'U950_ft6', 'V950_ft6', 'T950_ft6', 'U925_ft6', 'V925_ft6',
        'T925_ft6', 'R925_ft6', 'U850_ft6', 'V850_ft6', 'T850_ft6', 'R850_ft6',
        'GH500_ft6', 'T500_ft6', 'R500_ft6', 'GH300_ft6', 'U300_ft6', 'V300_ft6',
        'Prec_ft3', 'Prec_4_6h_sum'
    ],
    "target_variables": [
        'Prec_Target_ft4', 'Prec_Target_ft5', 'Prec_Target_ft6'
    ],
    # 2018å¹´ã¯ã†ã‚‹ã†å¹´ã§ã¯ãªã„ã®ã§365æ—¥ã€‚1æ—¥8å›æ›´æ–°ã€‚
    # 1ãƒ¶æœˆåˆ†(31æ—¥)ã®å ´åˆ: 31 * 8 = 248
    "time_steps_expected_year": 365 * 8,
    "time_steps_expected_month": 31 * 8
}
# --- è¦ä»¶å®šç¾©ã“ã“ã¾ã§ ---

def setup_logger(log_file_path):
    """ãƒ­ã‚¬ãƒ¼ã‚’è¨­å®šã—ã€ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«å‡ºåŠ›ã™ã‚‹ã‚ˆã†ã«ã™ã‚‹"""
    for handler in logging.root.handlers[:]:
        logging.root.removeHandler(handler)
    logging.basicConfig(
        level=logging.INFO,
        format='%(message)s',
        handlers=[
            logging.FileHandler(log_file_path, mode='w', encoding='utf-8'),
            logging.StreamHandler(sys.stdout)
        ]
    )

def validate_netcdf(file_path, reqs):
    """NetCDFãƒ•ã‚¡ã‚¤ãƒ«ãŒèª²é¡Œã®è¦ä»¶ã‚’æº€ãŸã—ã¦ã„ã‚‹ã‹è©³ç´°ã«æ¤œè¨¼ã™ã‚‹"""
    log_file = "check_nc.log"
    setup_logger(log_file)
    logging.info(f"NetCDFãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆ: {file_path}")
    logging.info(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆæ—¥æ™‚: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logging.info(f"ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«: {os.path.abspath(log_file)}\n")
    if not os.path.exists(file_path):
        logging.error(f"âŒ [ã‚¨ãƒ©ãƒ¼] æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
        return
    try:
        dataset = nc.Dataset(file_path, 'r')
    except OSError as e:
        logging.error(f"âŒ [ã‚¨ãƒ©ãƒ¼] ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã‘ã¾ã›ã‚“ã€‚ãƒ•ã‚¡ã‚¤ãƒ«ãŒç ´æã—ã¦ã„ã‚‹ã‹ã€NetCDFå½¢å¼ã§ã¯ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™: {e}")
        return

    # (ã“ã“ã‹ã‚‰ä¸‹ã®æ¤œè¨¼ãƒ­ã‚¸ãƒƒã‚¯ã¯å¤‰æ›´ã‚ã‚Šã¾ã›ã‚“)
    # --- 1. å¿…é ˆå¤‰æ•°ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯ ---
    logging.info("## 1. å¿…é ˆå¤‰æ•°ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯ ##")
    all_vars = list(dataset.variables.keys())
    missing_inputs = [v for v in reqs["input_variables"] if v not in all_vars]
    missing_targets = [v for v in reqs["target_variables"] if v not in all_vars]

    if not missing_inputs:
        logging.info("âœ… [OK] å…¨ã¦ã®å…¥åŠ›å¤‰æ•°ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚")
    else:
        logging.warning(f"âš ï¸ [WARN] ä¸è¶³ã—ã¦ã„ã‚‹å…¥åŠ›å¤‰æ•°ãŒã‚ã‚Šã¾ã™: {missing_inputs}")

    if not missing_targets:
        logging.info("âœ… [OK] å…¨ã¦ã®ç›®çš„å¤‰æ•°ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚")
    else:
        logging.warning(f"âš ï¸ [WARN] ä¸è¶³ã—ã¦ã„ã‚‹ç›®çš„å¤‰æ•°ãŒã‚ã‚Šã¾ã™: {missing_targets}")
    logging.info("-" * 50)

    # --- 2. æ¬¡å…ƒã¨åº§æ¨™ç³»ã®ãƒã‚§ãƒƒã‚¯ ---
    logging.info("## 2. æ¬¡å…ƒã¨åº§æ¨™ç³»ã®ãƒã‚§ãƒƒã‚¯ ##")
    # æ¬¡å…ƒã‚µã‚¤ã‚ºã®ãƒã‚§ãƒƒã‚¯
    for dim, size in reqs["dimensions"].items():
        if dim in dataset.dimensions and dataset.dimensions[dim].size == size:
            logging.info(f"âœ… [OK] æ¬¡å…ƒ '{dim}' ã®ã‚µã‚¤ã‚ºã¯æœŸå¾…é€šã‚Š ({size}) ã§ã™ã€‚")
        else:
            actual_size = dataset.dimensions.get(dim)
            actual_size = actual_size.size if actual_size else "å­˜åœ¨ã—ãªã„"
            logging.error(f"âŒ [NG] æ¬¡å…ƒ '{dim}' ã®ã‚µã‚¤ã‚ºãŒæœŸå¾…å€¤ ({size}) ã¨ç•°ãªã‚Šã¾ã™ã€‚å®Ÿéš›ã®ã‚µã‚¤ã‚º: {actual_size}")

    # åº§æ¨™å€¤ã®ãƒã‚§ãƒƒã‚¯
    for coord, expected_values in reqs["coordinates"].items():
        if coord in dataset.variables:
            actual_values = dataset.variables[coord][:]
            if np.allclose(actual_values, expected_values):
                logging.info(f"âœ… [OK] åº§æ¨™å¤‰æ•° '{coord}' ã®å€¤ã¯ä»•æ§˜ã¨ä¸€è‡´ã—ã¾ã™ã€‚")
            else:
                logging.warning(f"âš ï¸ [WARN] åº§æ¨™å¤‰æ•° '{coord}' ã®å€¤ãŒä»•æ§˜ã¨ã‚ãšã‹ã«ç•°ãªã‚Šã¾ã™ã€‚")
        else:
            logging.error(f"âŒ [NG] åº§æ¨™å¤‰æ•° '{coord}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    logging.info("-" * 50)
    
    # --- 3. æ™‚é–“è»¸ã®ãƒã‚§ãƒƒã‚¯ ---
    logging.info("## 3. æ™‚é–“è»¸ã®ãƒã‚§ãƒƒã‚¯ ##")
    if 'time' in dataset.dimensions:
        actual_steps = dataset.dimensions['time'].size
        logging.info(f"- æ¤œå‡ºã•ã‚ŒãŸæ™‚é–“ã‚¹ãƒ†ãƒƒãƒ—æ•°: {actual_steps}")
        
        # æœˆæ¬¡ãƒ•ã‚¡ã‚¤ãƒ«ã‹å¹´æ¬¡ãƒ•ã‚¡ã‚¤ãƒ«ã‹è‡ªå‹•ã§åˆ¤æ–­
        if actual_steps == reqs["time_steps_expected_year"]:
            logging.info(f"âœ… [OK] æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ—æ•°ã¯æœŸå¾…é€šã‚Šã§ã™ (1å¹´åˆ†: {reqs['time_steps_expected_year']})ã€‚")
        elif 240 <= actual_steps <= reqs["time_steps_expected_month"]: # 1ãƒ¶æœˆ(28-31æ—¥)ã®ç¯„å›²
            logging.info(f"âœ… [OK] æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ—æ•°ã¯æœˆæ¬¡ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦å¦¥å½“ã§ã™ã€‚")
        else:
            logging.warning(f"âš ï¸ [WARN] æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ—æ•°ãŒå¹´æ¬¡({reqs['time_steps_expected_year']})ã¾ãŸã¯æœˆæ¬¡({28*8}~{31*8})ã®æœŸå¾…å€¤ã¨ç•°ãªã‚Šã¾ã™ã€‚")
        
        if 'time' in dataset.variables:
            time_var = dataset.variables['time']
            dates = nc.num2date(time_var[:], units=time_var.units, calendar=time_var.calendar)
            
            # æ™‚é–“é–“éš”ãƒã‚§ãƒƒã‚¯
            diffs = np.diff(dates[:5])
            if all(d.total_seconds() == 3 * 3600 for d in diffs): # 3æ™‚é–“é–“éš”ã‹ãƒã‚§ãƒƒã‚¯
                logging.info("âœ… [OK] æ™‚é–“é–“éš”ã¯3æ™‚é–“ã§ä¸€å®šã®ã‚ˆã†ã§ã™ï¼ˆå†’é ­éƒ¨åˆ†ã§ç¢ºèªï¼‰ã€‚")
            else:
                logging.warning(f"âš ï¸ [WARN] æ™‚é–“é–“éš”ãŒ3æ™‚é–“ã§ä¸€å®šã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚é–“éš”: {[d.total_seconds()/3600 for d in diffs]} æ™‚é–“")
            
            # === è¿½åŠ éƒ¨åˆ†ï¼šåˆæœŸæ™‚åˆ»ã®åˆ†å¸ƒãƒã‚§ãƒƒã‚¯ ===
            logging.info("\n--- 3a. åˆæœŸæ™‚åˆ»ï¼ˆUTCï¼‰ã®åˆ†å¸ƒãƒã‚§ãƒƒã‚¯ ---")
            
            # å„åˆæœŸæ™‚åˆ»ã”ã¨ã®ãƒ‡ãƒ¼ã‚¿æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
            hour_counts = {}
            for date in dates:
                hour = date.hour
                if hour not in hour_counts:
                    hour_counts[hour] = 0
                hour_counts[hour] += 1
            
            # æœŸå¾…ã•ã‚Œã‚‹åˆæœŸæ™‚åˆ»
            expected_hours = [0, 3, 6, 9, 12, 15, 18, 21]
            
            # çµæœã‚’è¡¨ç¤º
            logging.info("åˆæœŸæ™‚åˆ»ã”ã¨ã®ãƒ‡ãƒ¼ã‚¿æ•°:")
            for hour in expected_hours:
                count = hour_counts.get(hour, 0)
                if count > 0:
                    logging.info(f"  - {hour:02d} UTC: {count} ãƒ‡ãƒ¼ã‚¿")
                else:
                    logging.warning(f"  - {hour:02d} UTC: {count} ãƒ‡ãƒ¼ã‚¿ âš ï¸ ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ï¼")
            
            # äºˆæœŸã—ãªã„æ™‚åˆ»ã®ãƒ‡ãƒ¼ã‚¿ãŒãªã„ã‹ãƒã‚§ãƒƒã‚¯
            unexpected_hours = set(hour_counts.keys()) - set(expected_hours)
            if unexpected_hours:
                logging.warning(f"âš ï¸ [WARN] äºˆæœŸã—ãªã„åˆæœŸæ™‚åˆ»ã®ãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã¾ã™: {sorted(unexpected_hours)}")
            else:
                logging.info("âœ… [OK] å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ãŒæœŸå¾…ã•ã‚Œã‚‹åˆæœŸæ™‚åˆ»ï¼ˆ00, 03, 06, 09, 12, 15, 18, 21 UTCï¼‰ã‹ã‚‰å–å¾—ã•ã‚Œã¦ã„ã¾ã™ã€‚")
            
            # å„æ—¥ã®åˆæœŸæ™‚åˆ»ã®å®Œå…¨æ€§ã‚’ãƒã‚§ãƒƒã‚¯
            logging.info("\n--- 3b. æ—¥åˆ¥ã®åˆæœŸæ™‚åˆ»å®Œå…¨æ€§ãƒã‚§ãƒƒã‚¯ ---")
            
            # æ—¥ä»˜ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
            daily_hours = {}
            for date in dates:
                day_key = date.strftime('%Y-%m-%d')
                if day_key not in daily_hours:
                    daily_hours[day_key] = set()
                daily_hours[day_key].add(date.hour)
            
            # ä¸å®Œå…¨ãªæ—¥ã‚’ãƒã‚§ãƒƒã‚¯
            incomplete_days = []
            for day, hours in sorted(daily_hours.items()):
                missing_hours = set(expected_hours) - hours
                if missing_hours:
                    incomplete_days.append((day, sorted(missing_hours)))
            
            if incomplete_days:
                logging.warning(f"âš ï¸ [WARN] ä»¥ä¸‹ã®æ—¥ã§ä¸€éƒ¨ã®åˆæœŸæ™‚åˆ»ã®ãƒ‡ãƒ¼ã‚¿ãŒæ¬ ã‘ã¦ã„ã¾ã™:")
                for day, missing in incomplete_days[:5]:  # æœ€åˆã®5æ—¥åˆ†ã®ã¿è¡¨ç¤º
                    logging.warning(f"  - {day}: æ¬ è½æ™‚åˆ» {missing}")
                if len(incomplete_days) > 5:
                    logging.warning(f"  ... ä»– {len(incomplete_days) - 5} æ—¥")
            else:
                logging.info("âœ… [OK] å…¨ã¦ã®æ—¥ã§8ã¤ã®åˆæœŸæ™‚åˆ»ï¼ˆ3æ™‚é–“ã”ã¨ï¼‰ã®ãƒ‡ãƒ¼ã‚¿ãŒæƒã£ã¦ã„ã¾ã™ã€‚")
            
            # === è¿½åŠ éƒ¨åˆ†çµ‚äº† ===
            
        else:
            logging.error("âŒ [NG] 'time' å¤‰æ•°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    else:
        logging.error("âŒ [NG] 'time' æ¬¡å…ƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    logging.info("-" * 50)

    # --- 4. ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯ (æ¬ æå€¤ & æ•´åˆæ€§) ---
    logging.info("## 4. ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯ ##")
    logging.info("--- 4a. å„å¤‰æ•°ã®æ¬ æå€¤ï¼ˆNaNï¼‰ã®å‰²åˆ ---")
    for var_name, var_obj in dataset.variables.items():
        if len(var_obj.shape) > 1:
            data = var_obj[:]
            nan_count = np.isnan(data).sum()
            if hasattr(var_obj, '_FillValue'):
                fill_value = var_obj._FillValue
                if not np.isnan(fill_value):
                    nan_count += (data == fill_value).sum()
            total_count = data.size
            if total_count > 0:
                nan_percentage = (nan_count / total_count) * 100
                log_msg = f"- {var_name}: {nan_percentage:.2f}%"
                if nan_percentage > 50:
                    logging.warning(f"âš ï¸ {log_msg}  <-- æ¬ æå€¤ãŒ50%ã‚’è¶…ãˆã¦ã„ã¾ã™ï¼")
                else:
                    logging.info(log_msg)
    logging.info("\n--- 4b. é™æ°´é‡ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ ---")
    prec_sum_var = 'Prec_4_6h_sum'
    target_prec_vars = ['Prec_Target_ft4', 'Prec_Target_ft5', 'Prec_Target_ft6']
    if all(v in dataset.variables for v in [prec_sum_var] + target_prec_vars):
        sum_data = dataset.variables[prec_sum_var][:]
        target_sum = np.zeros_like(sum_data, dtype=np.float32)
        for var in target_prec_vars:
            target_sum += dataset.variables[var][:]
        mask = ~np.isnan(sum_data) & ~np.isnan(target_sum)
        diff = np.abs(sum_data[mask] - target_sum[mask])
        if np.allclose(sum_data[mask], target_sum[mask]):
            logging.info("âœ… [OK] Prec_4_6h_sum ã¯ã€ft4, ft5, ft6 ã®åˆè¨ˆã¨ä¸€è‡´ã—ã¾ã—ãŸã€‚")
        else:
            logging.warning(f"âš ï¸ [WARN] Prec_4_6h_sum ã¨ ft4,5,6ã®åˆè¨ˆãŒä¸€è‡´ã—ã¾ã›ã‚“ã€‚å¹³å‡çµ¶å¯¾èª¤å·®: {diff.mean():.6f}")
    else:
        logging.warning("âš ï¸ [WARN] é™æ°´é‡ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ã«å¿…è¦ãªå¤‰æ•°ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")

    dataset.close()
    logging.info("\næ¤œè¨¼ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")


if __name__ == "__main__":
    # ğŸ’¡---ã“ã“ã‹ã‚‰ä¿®æ­£---
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å—ã‘å–ã‚‹ã‚ˆã†ã«å¤‰æ›´
    parser = argparse.ArgumentParser(description="NetCDFãƒ•ã‚¡ã‚¤ãƒ«ã®èª²é¡Œè¦ä»¶é©åˆæ€§ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚")
    parser.add_argument("netcdf_file", type=str, help="æ¤œè¨¼ã™ã‚‹NetCDFãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹")
    args = parser.parse_args()

    # å¼•æ•°ã§å—ã‘å–ã£ãŸãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ä½¿ã£ã¦æ¤œè¨¼ã‚’å®Ÿè¡Œ
    validate_netcdf(args.netcdf_file, REQUIREMENTS)
    # ğŸ’¡---ã“ã“ã¾ã§ä¿®æ­£---
    # python check_nc.py output_nc/201801.nc